apiVersion: batch/v1
kind: Job
metadata:
  name: tfssdmobilenetss1-gpu-workload
  labels:
    app: tfssdmobilenetss-gpu-workload
spec:
  parallelism: 1
  completions: 1
  template:
    metadata:
      name: tfssdmobilenetss1-gpu-pod
      labels:
        app: tfssdmobilenetss-gpu-pod
        GPU_MEM_REQ: "10"
    spec:
      schedulerName: custom-scheduler
      restartPolicy: OnFailure 
      containers:
      - name: mlperf-infer-imgclassify-tf-ssdmob-gpu-container
        image: aferikoglou/mlperf-infer-imgclassify-tf-ssdmob-gpu:latest
        command: ['sh', '-c', 'cp /tmp/coco.py /tmp/inference/v0.5/classification_and_detection/python && cp /tmp/backend_tf.py /tmp/inference/v0.5/classification_and_detection/python && cd /tmp/inference/v0.5/classification_and_detection && MODEL_DIR=/tmp/models/ssd-mobilenet-default DATA_DIR=/tmp/dataset ./run_local.sh tf ssd-mobilenet gpu --scenario SingleStream']
#        resources:
#          limits:
#            aferik.com/gpu-mem: 10
