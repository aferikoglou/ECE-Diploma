apiVersion: batch/v1
kind: Job
metadata:
  name: coco300-gpu-workload
  labels:
    app: coco300-gpu-workload
spec:
  parallelism: 2
  completions: 2
  template:
    metadata:
      name: coco300-gpu-pod
      labels:
        app: coco300-gpu-pod
    spec:
      restartPolicy: OnFailure 
      containers:
      - name: mlperf-infer-imgclassify-tf-ssdmob-gpu-container
        image: aferikoglou/mlperf-infer-imgclassify-tf-ssdmob-gpu:latest
        command: ['sh', '-c', 'cp /tmp/coco.py /tmp/inference/v0.5/classification_and_detection/python && cd /tmp/inference/v0.5/classification_and_detection && MODEL_DIR=/tmp DATA_DIR=/tmp ./run_local.sh tf ssd-mobilenet gpu']
        resources:
          limits:
            aliyun.com/gpu-mem: 31
