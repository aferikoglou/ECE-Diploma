apiVersion: batch/v1
kind: Job
metadata:
  name: onnx-mobilenet-1024-1
spec:
  completions: 1
  parallelism: 1
  template:
    metadata:
      name: onnx-mobilenet-1024-1-pod
    spec:
      containers:
      - command:
        - sh
        - -c
        - cp /root/configs/1024/mlperf.conf /root/inference/v0.5/ && cd /root/inference/v0.5/classification_and_detection
          && MODEL_DIR=/root/models/onnx-mobilenet DATA_DIR=/root/datasets/fake-imagenet
          ./run_local.sh onnxruntime mobilenet gpu --scenario SingleStream
        image: aferikoglou/mlperf-inference:latest
        name: mlperf-inference-container
        resources:
          limits:
            nvidia.com/gpu: 1
      restartPolicy: OnFailure
