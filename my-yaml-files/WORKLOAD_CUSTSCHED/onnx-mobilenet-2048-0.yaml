apiVersion: batch/v1
kind: Job
metadata:
  name: onnx-mobilenet-2048-0
spec:
  completions: 1
  parallelism: 1
  template:
    metadata:
      labels:
        GPU_MEM_REQ: '2'
      name: onnx-mobilenet-2048-0-pod
    spec:
      containers:
      - command:
        - sh
        - -c
        - cp /root/configs/2048/mlperf.conf /root/inference/v0.5/ && cd /root/inference/v0.5/classification_and_detection
          && MODEL_DIR=/root/models/onnx-mobilenet DATA_DIR=/root/datasets/fake-imagenet
          ./run_local.sh onnxruntime mobilenet gpu --scenario SingleStream
        image: aferikoglou/mlperf-inference:latest
        name: mlperf-inference-container
      restartPolicy: OnFailure
      schedulerName: custom-scheduler
